{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c33cad57",
   "metadata": {
    "id": "860f20b3"
   },
   "source": [
    "# üéØ **Introduction to Darts: A Time Series Library** üìà\n",
    "\n",
    "üîç **What is Darts?**\n",
    "Darts is an amazing Python library that specializes in time series analysis and forecasting. üïí It provides a wide range of functionality and tools for working with time series data, making it an essential package for anyone interested in exploring and modeling temporal patterns. üí™\n",
    "\n",
    "üåü **Why is Darts Good?**\n",
    "Darts stands out for several reasons:\n",
    "\n",
    "1. **User-Friendly**: Darts is designed to be beginner-friendly, making it accessible to students and researchers new to time series analysis. üìö\n",
    "\n",
    "2. **Extensive Functionality**: It offers a vast array of tools, models, and algorithms for time series manipulation, forecasting, and evaluation. üß∞\n",
    "\n",
    "3. **Integration with Pandas**: Darts seamlessly integrates with the widely-used pandas library, allowing users to leverage the power of Pandas' DataFrames for time series handling. üêº\n",
    "\n",
    "4. **Visualization Capabilities**: Darts provides intuitive plotting functions, enabling users to visualize time series and forecasted values effortlessly. üìä\n",
    "\n",
    "5. **Modularity and Extendability**: Darts follows a modular design, making it easy to combine and extend functionalities, enabling users to experiment with different models and techniques. üß©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acaceb5",
   "metadata": {
    "id": "2b3c46a4"
   },
   "source": [
    "### Set-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dce6ca8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-15T14:26:19.029308Z",
     "iopub.status.busy": "2025-05-15T14:26:19.028963Z",
     "iopub.status.idle": "2025-05-15T14:31:27.621701Z",
     "shell.execute_reply": "2025-05-15T14:31:27.620083Z",
     "shell.execute_reply.started": "2025-05-15T14:26:19.029288Z"
    },
    "id": "1aed58c6",
    "outputId": "6dee32fe-d17a-4de4-aebe-d14520f80c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.4.4\n",
      "  Using cached pandas-1.4.4.tar.gz (4.9 MB)\n",
      "  Installing build dependencies ... done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001bdone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?done\n",
      "\u001b[?25hCollecting protobuf<3.20\n",
      "  Downloading protobuf-3.19.6-py2.py3-none-any.whl.metadata (828 bytes)\n",
      "Collecting darts==0.30.0\n",
      "  Downloading darts-0.30.0-py3-none-any.whl.metadata (52 kB)\n",
      "Collecting prophet==1.1.5\n",
      "  Downloading prophet-1.1.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from pandas==1.4.4) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from pandas==1.4.4) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from pandas==1.4.4) (2025.1)\n",
      "Collecting holidays>=0.11.1 (from darts==0.30.0)\n",
      "  Downloading holidays-0.72-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: joblib>=0.16.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from darts==0.30.0) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from darts==0.30.0) (3.10.0)\n",
      "Collecting nfoursid>=1.0.0 (from darts==0.30.0)\n",
      "  Downloading nfoursid-1.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pmdarima>=1.8.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from darts==0.30.0) (2.0.4)\n",
      "Collecting pyod>=0.9.5 (from darts==0.30.0)\n",
      "  Downloading pyod-2.0.5-py3-none-any.whl.metadata (46 kB)\n",
      "Requirement already satisfied: requests>=2.22.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from darts==0.30.0) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from darts==0.30.0) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from darts==0.30.0) (1.13.1)\n",
      "Collecting shap>=0.40.0 (from darts==0.30.0)\n",
      "  Downloading shap-0.47.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting statsforecast>=1.4 (from darts==0.30.0)\n",
      "  Downloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: statsmodels>=0.14.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from darts==0.30.0) (0.14.4)\n",
      "Collecting tbats>=1.1.0 (from darts==0.30.0)\n",
      "  Downloading tbats-1.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.60.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from darts==0.30.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from darts==0.30.0) (4.12.2)\n",
      "Collecting xarray>=0.17.0 (from darts==0.30.0)\n",
      "  Downloading xarray-2025.4.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: xgboost>=1.6.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from darts==0.30.0) (2.1.4)\n",
      "Collecting pytorch-lightning>=1.5.0 (from darts==0.30.0)\n",
      "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting tensorboardX>=2.1 (from darts==0.30.0)\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from darts==0.30.0) (2.6.0+cpu.cxx11.abi)\n",
      "Collecting cmdstanpy>=1.0.4 (from prophet==1.1.5)\n",
      "  Downloading cmdstanpy-1.2.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: importlib-resources in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from prophet==1.1.5) (6.5.2)\n",
      "Collecting stanio<2.0.0,>=0.4.0 (from cmdstanpy>=1.0.4->prophet==1.1.5)\n",
      "  Downloading stanio-0.5.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts==0.30.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts==0.30.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts==0.30.0) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts==0.30.0) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts==0.30.0) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts==0.30.0) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts==0.30.0) (3.2.1)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from pmdarima>=1.8.0->darts==0.30.0) (3.0.12)\n",
      "Requirement already satisfied: urllib3 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from pmdarima>=1.8.0->darts==0.30.0) (2.3.0)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from pmdarima>=1.8.0->darts==0.30.0) (75.8.0)\n",
      "Collecting numba>=0.51 (from pyod>=0.9.5->darts==0.30.0)\n",
      "  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from python-dateutil>=2.8.1->pandas==1.4.4) (1.17.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from pytorch-lightning>=1.5.0->darts==0.30.0) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.30.0) (2025.2.0)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=1.5.0->darts==0.30.0)\n",
      "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=1.5.0->darts==0.30.0)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from requests>=2.22.0->darts==0.30.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from requests>=2.22.0->darts==0.30.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from requests>=2.22.0->darts==0.30.0) (2025.1.31)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from scikit-learn>=1.0.1->darts==0.30.0) (3.5.0)\n",
      "Collecting slicer==0.0.8 (from shap>=0.40.0->darts==0.30.0)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting cloudpickle (from shap>=0.40.0->darts==0.30.0)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting coreforecast>=0.0.12 (from statsforecast>=1.4->darts==0.30.0)\n",
      "  Downloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting fugue>=0.8.1 (from statsforecast>=1.4->darts==0.30.0)\n",
      "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting utilsforecast>=0.1.4 (from statsforecast>=1.4->darts==0.30.0)\n",
      "  Downloading utilsforecast-0.2.12-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from statsmodels>=0.14.0->darts==0.30.0) (1.0.1)\n",
      "INFO: pip is looking at multiple versions of tensorboardx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorboardX>=2.1 (from darts==0.30.0)\n",
      "  Downloading tensorboardX-2.6.1-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading tensorboardX-2.6-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: filelock in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from torch>=1.8.0->darts==0.30.0) (3.17.0)\n",
      "Requirement already satisfied: networkx in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from torch>=1.8.0->darts==0.30.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from torch>=1.8.0->darts==0.30.0) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from torch>=1.8.0->darts==0.30.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->darts==0.30.0) (1.3.0)\n",
      "INFO: pip is looking at multiple versions of xarray to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting xarray>=0.17.0 (from darts==0.30.0)\n",
      "  Downloading xarray-2025.3.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading xarray-2025.3.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading xarray-2025.1.2-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2025.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2025.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2024.11.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "INFO: pip is still looking at multiple versions of xarray to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading xarray-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2024.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2024.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading xarray-2024.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2024.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2024.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2023.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from xgboost>=1.6.0->darts==0.30.0) (2.26.2.post1)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.30.0)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting triad>=0.9.7 (from fugue>=0.8.1->statsforecast>=1.4->darts==0.30.0)\n",
      "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting adagio>=0.2.4 (from fugue>=0.8.1->statsforecast>=1.4->darts==0.30.0)\n",
      "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51->pyod>=0.9.5->darts==0.30.0)\n",
      "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->darts==0.30.0) (3.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.30.0)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.30.0)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.30.0) (25.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.30.0)\n",
      "  Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.30.0)\n",
      "  Downloading multidict-6.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.30.0)\n",
      "  Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.30.0)\n",
      "  Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in /home/saranjthilak92/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts==0.30.0) (19.0.1)\n",
      "Collecting fs (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts==0.30.0)\n",
      "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts==0.30.0)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Downloading darts-0.30.0-py3-none-any.whl (917 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m917.3/917.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading prophet-1.1.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.4/14.4 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
      "Downloading cmdstanpy-1.2.5-py3-none-any.whl (94 kB)\n",
      "Downloading holidays-0.72-py3-none-any.whl (932 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m932.3/932.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading nfoursid-1.0.1-py3-none-any.whl (16 kB)\n",
      "Downloading pyod-2.0.5-py3-none-any.whl (200 kB)\n",
      "Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shap-0.47.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n",
      "Downloading tbats-1.1.3-py3-none-any.whl (44 kB)\n",
      "Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
      "Downloading xarray-2023.12.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Downloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
      "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading stanio-0.5.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading utilsforecast-0.2.12-py3-none-any.whl (42 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
      "Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "Downloading multidict-6.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (245 kB)\n",
      "Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (349 kB)\n",
      "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Building wheels for collected packages: pandas\n",
      "  Building wheel for pandas (p^C\n",
      "\u001b[?25canceled\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'darts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install pandas==1.4.4 \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotobuf<3.20\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m darts==0.30.0 prophet==1.1.5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdarts\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDarts version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdarts\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'darts'"
     ]
    }
   ],
   "source": [
    "!pip install pandas==1.4.4 \"protobuf<3.20\" darts==0.30.0 prophet==1.1.5\n",
    "\n",
    "import darts\n",
    "print(f\"Darts version: {darts.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4587ea95",
   "metadata": {
    "id": "2f5c17d4"
   },
   "source": [
    "2. **Loading and Visualizing Time Series Data with Pandas and Darts** üìä\n",
    "   - Import the necessary libraries.\n",
    "   - Load sample [weather](https://wagon-public-datasets.s3.amazonaws.com/weather.csv) and [ice cream](https://wagon-public-datasets.s3.amazonaws.com/ice_cream.csv) time series dataset. This is pulled from [Google Trends](https://trends.google.com/trends/)! We've just taken data for searches on \"ice cream\" and \"hot weather\" from 2004. Feel free to check out your own data-sets down the line!\n",
    "   - Demonstrate how to create a Darts TimeSeries object from a Pandas DataFrame.\n",
    "   - Plot the time series using Darts' visualization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb345584",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.status.busy": "2025-05-15T14:31:27.624238Z",
     "iopub.status.idle": "2025-05-15T14:31:27.624557Z",
     "shell.execute_reply": "2025-05-15T14:31:27.624421Z",
     "shell.execute_reply.started": "2025-05-15T14:31:27.624406Z"
    },
    "id": "c2b798ee-096d-4934-9fca-877c7c054213",
    "outputId": "73cd7051-6485-4c64-fdff-7871a5feca1d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load a sample time series dataset\n",
    "# Skip the first 2 rows when reading the CSV\n",
    "df = pd.read_csv(\"ice_cream.csv\", header=1, names=['Month', 'ice_cream'])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf6a90b",
   "metadata": {},
   "source": [
    "First up let's see how easy it is to load up our time series in a TimeSeries object and plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8244f20c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2025-05-15T14:31:27.625437Z",
     "iopub.status.idle": "2025-05-15T14:31:27.625760Z",
     "shell.execute_reply": "2025-05-15T14:31:27.625626Z",
     "shell.execute_reply.started": "2025-05-15T14:31:27.625611Z"
    },
    "id": "8bcc1ae0-bbbb-4b2d-9fa5-378f94ec8dda",
    "outputId": "cc8f1b65-5863-4dc6-a022-32985be5208e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "series = TimeSeries.from_dataframe(df, 'Month', 'ice_cream')\n",
    "series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25328cf6",
   "metadata": {},
   "source": [
    "Uh oh - looks like we have some issues and missing values üòî This is a super common issue with many time series! Let's move on to preprocessing to showcase some methods for handling issues like these!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d9a00",
   "metadata": {
    "id": "a11fa28e"
   },
   "source": [
    "### **Manipulating Time Series Data** üîÑ\n",
    "   - Showcase various operations for manipulating time series data:\n",
    "     - Resampling and frequency conversion.\n",
    "     - Handling missing values.\n",
    "     - Applying rolling window calculations.\n",
    "     - Feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0458a1e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-15T14:31:27.626383Z",
     "iopub.status.idle": "2025-05-15T14:31:27.626667Z",
     "shell.execute_reply": "2025-05-15T14:31:27.626542Z",
     "shell.execute_reply.started": "2025-05-15T14:31:27.626528Z"
    },
    "id": "0eaf5a71-2596-43fb-a55e-c253e7effeaf"
   },
   "outputs": [],
   "source": [
    "from darts.utils.missing_values import fill_missing_values\n",
    "series = fill_missing_values(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf31a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "05dfd8b3-f174-4b8c-bcdb-dc16052c130d",
    "outputId": "12bfea75-b7b0-40c3-9000-fed1285eedff"
   },
   "outputs": [],
   "source": [
    "series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eed45e",
   "metadata": {
    "id": "42b96890-b774-4c8e-bfaf-b901ff209601"
   },
   "source": [
    "Easy! What if we want to plot our data on an annual basis instead? We can just resample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20557867",
   "metadata": {
    "id": "86152e15-c9a7-46ef-9eac-5e1735abcb1d"
   },
   "outputs": [],
   "source": [
    "# Resampling and frequency conversion\n",
    "resampled_example = series.resample(\"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4107a47a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "8ab289c8-4ac0-4bc2-a9da-bd90e3d9e8f0",
    "outputId": "e0f462be-0606-4f70-a432-9a7f217ad0cd"
   },
   "outputs": [],
   "source": [
    "resampled_example.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25706b4e",
   "metadata": {
    "id": "86988b83-214e-4bec-8bf7-ceab435375c6"
   },
   "outputs": [],
   "source": [
    "# Applying rolling window calculations\n",
    "rolling_mean_example = series.window_transform({\"function\":\"mean\", \"window\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187d2d3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "089a8df1-e7f6-485e-b7a7-948a1640667b",
    "outputId": "d8f3a18e-39a2-44d9-df1b-20d31cc30526"
   },
   "outputs": [],
   "source": [
    "rolling_mean_example.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc40544e",
   "metadata": {
    "id": "b2fd0ac8-a626-4d3a-b512-a9e99dd2daa3"
   },
   "source": [
    "We can diff our series just like we did with Pandas earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426a56d6",
   "metadata": {
    "id": "3785e3b3-8ab8-4515-b762-3297cd715067"
   },
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "diff_example = series.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216591cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "cb60cc35-23da-48db-acb6-1dd5d3921b10",
    "outputId": "90de03d2-731a-4334-e6fa-6c0364628d92"
   },
   "outputs": [],
   "source": [
    "diff_example.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408f3582",
   "metadata": {
    "id": "27b9e865-4a0c-4efd-b080-9213805163d6"
   },
   "source": [
    "We can even add holidays to our time series with a quick method - this will add a simple 0 or 1 based on whether or not there was a national holiday on that day. If we wanted, we can then use this to spot more correlations later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace62c9b",
   "metadata": {
    "id": "e3632c8d-e196-4071-bfa3-7ffd297d27bb"
   },
   "outputs": [],
   "source": [
    "hol_example = series.add_holidays(\"US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b6df6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "1917842e-b654-4d4f-b29f-2a9274dc1930",
    "outputId": "1fb77abb-c011-47d9-b908-d7c1c091bac1"
   },
   "outputs": [],
   "source": [
    "hol_example.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8cdc72",
   "metadata": {
    "id": "ad6beb3e"
   },
   "source": [
    "### Time Series Modeling and Forecasting ‚è≥\n",
    "   - Now we can split our data and begin modelling:\n",
    "     - Naive models (e.g., NaiveSeasonal).\n",
    "     - Classical models (e.g., ExponentialSmoothing).\n",
    "     - Machine learning models (e.g., Prophet, ARIMA).\n",
    "   - Demonstrate how to fit models to time series data and generate forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17591b12",
   "metadata": {
    "id": "06a9758e-ef5b-42cf-9598-656d5364662a"
   },
   "source": [
    "First let's standardize and log our time series since it seems to have an exponential trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a36ad4",
   "metadata": {
    "id": "91246744-33b9-4aaf-a323-42141686245f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "logged = (series).map(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee6e3e",
   "metadata": {
    "id": "33cafcac-de8c-4440-beb1-da3bdc9fb94e"
   },
   "outputs": [],
   "source": [
    "from darts.dataprocessing.transformers.scaler import Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c61a2",
   "metadata": {},
   "source": [
    "Next we can easily implement a MinMaxScaler() for our data (in this case - all Google Trends are standardized to 100 so we could just divide by 100, but it's useful to demonstrate!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44449ce3",
   "metadata": {
    "id": "0ba23a47-d6f7-4e31-80ef-f78601dde911"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa118c4",
   "metadata": {
    "id": "a43dd128-783e-4fcb-adfb-09cf51d7eeea"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23961a",
   "metadata": {
    "id": "c83c141d-c85e-4867-9e8a-f20482f7b3a3"
   },
   "outputs": [],
   "source": [
    "ts_transformer = Scaler(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fbe39c",
   "metadata": {
    "id": "c6350e60-ff17-479b-af7e-cb61fc604292"
   },
   "outputs": [],
   "source": [
    "scaled_ts = ts_transformer.fit_transform(logged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b92b66d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "ff0aa2c2-087d-4eea-b496-25fe2f5fe7b2",
    "outputId": "33aab9ef-823a-4457-b13c-3ec2ee037f17"
   },
   "outputs": [],
   "source": [
    "train, val = (scaled_ts).split_before(0.8)# (we standardize by dividing by 100 since Google Trends data tops out at 100 by default!)\n",
    "train.plot(label=\"training\")\n",
    "val.plot(label=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e048d414",
   "metadata": {
    "id": "82705680-d995-424c-aa75-20f92ba34559"
   },
   "source": [
    "First, let's define our baseline model with a NaiveSeasonal model (when K = 1 it will simply repeat the prior timestep!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d1c14d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "b02210d9-89b0-4ca1-869a-182f8acedb39",
    "outputId": "56a8ee4d-52a3-4b7e-90ff-fb4d5a5f2b3b"
   },
   "outputs": [],
   "source": [
    "from darts.models import NaiveSeasonal\n",
    "\n",
    "naive_model = NaiveSeasonal(K=1)\n",
    "naive_model.fit(train)\n",
    "naive_forecast = naive_model.predict(len(val))\n",
    "\n",
    "train.plot(label=\"actual\")\n",
    "val.plot(label = \"validation\")\n",
    "naive_forecast.plot(label=\"naive forecast (K=1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93020567",
   "metadata": {
    "id": "5130404f-4ca0-49d6-b71c-c054f781dc10"
   },
   "source": [
    "Not great! Let's quantify our baseline with MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9871d153",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "848c515b-05ac-4b2d-bb53-65f87e04e43f",
    "outputId": "a328b2c3-ba79-47ca-8d6f-12778569e03f"
   },
   "outputs": [],
   "source": [
    "from darts.metrics import mape\n",
    "\n",
    "accuracy = mape(val, naive_forecast)\n",
    "print(f\"Mean Absolute Percentage Error: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06022002",
   "metadata": {
    "id": "2333f394-219d-44f9-baaf-b8b3297a156c"
   },
   "source": [
    "Should be quite an easy baseline to beat! Let's try using an Exponential Smoothing model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99290347",
   "metadata": {
    "id": "f5555bf6"
   },
   "outputs": [],
   "source": [
    "from darts.models import ExponentialSmoothing\n",
    "\n",
    "# Initialize and fit an Exponential Smoothing model\n",
    "model = ExponentialSmoothing()\n",
    "model.fit(train)\n",
    "\n",
    "# Generate forecasts\n",
    "exp_forecast = model.predict(len(val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb5424",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "19873815-df7b-47e9-ad16-993856b6741f",
    "outputId": "cd04950e-a7bc-42a5-e900-d3b42f687850"
   },
   "outputs": [],
   "source": [
    "train.plot(label=\"training\")\n",
    "val.plot(label=\"validation\")\n",
    "exp_forecast.plot(label = \"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3c8a5d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "470141fd-3786-4096-a0bb-1f9858e4e66c",
    "outputId": "d9c556b2-a507-4196-e1e7-168d46d762db"
   },
   "outputs": [],
   "source": [
    "from darts.metrics import mape\n",
    "\n",
    "accuracy = mape(val, exp_forecast)\n",
    "print(f\"Mean Absolute Percentage Error: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d501b8",
   "metadata": {
    "id": "dceaeb0b-74ae-4175-b0e9-f89e1ffeff10"
   },
   "source": [
    "Already quite a bit better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a2e78",
   "metadata": {
    "id": "40ba4566-a378-4a74-9c28-bb4342b9c61d",
    "tags": []
   },
   "source": [
    "### Multiple models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1dedc8",
   "metadata": {
    "id": "a3a8343e-ff84-4cc0-bc59-d0c54111b80c"
   },
   "source": [
    "Darts makes it incredibly easy to loop through a list of models to see which performs best for our task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a2ffa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3239b826-1440-4bab-bb54-c1264424c06a",
    "outputId": "cc56352b-29bb-4c03-9ae5-14b328d62bc5"
   },
   "outputs": [],
   "source": [
    "from darts.models import AutoARIMA, Prophet, TBATS\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for model in [AutoARIMA, Prophet, TBATS]:\n",
    "    temp = model()\n",
    "    temp.fit(train)\n",
    "    preds = temp.predict(len(val))\n",
    "    accuracy = mape(val, preds)\n",
    "    results_dict[f\"{model}\"] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acececf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "051bba12-fa87-4ea7-a868-d1ae73de22b5",
    "outputId": "9d61c365-0788-4004-ce7f-1f32d550ef48"
   },
   "outputs": [],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d6a85c",
   "metadata": {
    "id": "b7cc9af5-7b79-4091-831e-838b39dbe3a8"
   },
   "source": [
    "It seems TBATS (a model that decomposes a time series into multiple components, including trend, seasonality, and error terms before representing each as a combination of trigonometric functions) has worked best! Could we do any better with some exogenous features though?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f30b116",
   "metadata": {
    "id": "fcd3bc3b-81b5-4cb0-9e33-e75807cc41e9"
   },
   "source": [
    "### Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb9a2d3",
   "metadata": {
    "id": "53dcaf7f-9147-4cc5-99fd-8de743afb875"
   },
   "source": [
    "Reminder: Covariates refer to external data that can be used as inputs to models to help improve forecasts. In the context of forecasting models, the target is the series to be forecasted/predicted, and the covariates themselves are not predicted. We distinguish three kinds of covariates:\n",
    "\n",
    "Past covariates are (by definition) covariates known only into the past (e.g. measurements)\n",
    "\n",
    "Future covariates are (by definition) covariates known into the future (e.g., weather forecasts)\n",
    "\n",
    "Static covariates are (by definition) covariates constant over time (e.g., product IDs). \n",
    "\n",
    "Check out [this page](https://unit8co.github.io/darts/#:~:text=Darts%20is%20a%20Python%20library,%2C%20similar%20to%20scikit%2Dlearn.) to see which models have the availability to fold in past and future covariates. To keep things simple we'll proceed with Arima!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4024649",
   "metadata": {
    "id": "8719fc9f-491d-40ba-ad44-0b2795ede558"
   },
   "source": [
    "<img src = \"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/05-ML/09-Time-Series/covatiates.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7a2b2",
   "metadata": {
    "id": "d8e14f9b-83ba-4315-86a6-08e6f6b430d5"
   },
   "source": [
    "Let's try folding in some covariates for our ice_cream sales - what about searches for \"hot weather\"? (This will essentially act as a proxy for weather forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3f9c8",
   "metadata": {
    "id": "410592dc-d7d1-421d-b4a7-57bebad693da"
   },
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(\"weather.csv\", header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac515d",
   "metadata": {},
   "source": [
    "We create a time series just as we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c345c4",
   "metadata": {
    "id": "7b9dee9b-3ebb-4702-820c-4da468c7dc30"
   },
   "outputs": [],
   "source": [
    "weather_ts = TimeSeries.from_dataframe(weather_df, time_col=\"Month\", value_cols=\"hot weather: (United States)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5565df5c",
   "metadata": {},
   "source": [
    "Let's visualize the two side by side to see if they look aligned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c04292",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_ts.plot()\n",
    "scaled_ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551b5b25",
   "metadata": {},
   "source": [
    "We'll need to apply the same scaling procedures as before so we can properly compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74eff11",
   "metadata": {
    "id": "efd9d463-fb52-4de9-b712-6172ffe8e168"
   },
   "outputs": [],
   "source": [
    "preproc_weather = ts_transformer.fit_transform(weather_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c43a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_weather.plot(label = \"weather searches\")\n",
    "scaled_ts.plot(label = \"ice cream searches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fab21e",
   "metadata": {
    "id": "0b0272e8-98e5-45f2-a152-5990182b5e48"
   },
   "source": [
    "There seems to be quite a strong correlation between the two. If we add future predictions for \"hot weather\" searches (which would probably be quite similar to just a regular weather forecast), does our model get better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfea35f5",
   "metadata": {
    "id": "59914c9d-c690-4c9b-9847-78d40632b13e"
   },
   "source": [
    "Let's try it with a simple AutoArima Model and no covariates before we add them in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d4dbfd",
   "metadata": {
    "id": "2ea22cd9-914b-40fe-a481-073181e1598b"
   },
   "outputs": [],
   "source": [
    "model = AutoARIMA()\n",
    "\n",
    "# w no covariates\n",
    "model.fit(train)\n",
    "# predict on our val\n",
    "base_preds = model.predict(len(val))\n",
    "# calculate mape\n",
    "accuracy = mape(val, base_preds)\n",
    "# add it to a comparison dict\n",
    "covariates_dict = {}\n",
    "covariates_dict[\"no_covariates\"] = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7646d71",
   "metadata": {
    "id": "c5d0ba3f-5680-43c4-aeb7-c823e422fe09"
   },
   "source": [
    "Now we fold in future covariates (i.e. our future prediction data for hot weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7900d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariate_model = AutoARIMA()\n",
    "# w future covariates only\n",
    "covariate_model.fit(train, future_covariates = preproc_weather)\n",
    "base_preds = covariate_model.predict(len(val), future_covariates=preproc_weather)\n",
    "accuracy = mape(val, base_preds)\n",
    "covariates_dict[f\"future_covariates\"] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c742bc77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7bc3de5-7495-48d5-9c60-3a53a9e8d727",
    "outputId": "337b1b7f-671f-498b-d823-b9aed5821742"
   },
   "outputs": [],
   "source": [
    "covariates_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e16a34",
   "metadata": {},
   "source": [
    "Our error is down to just versus the original 20%. Darts makes it so easy to fold in as many different covariate series as we want to - all we have to do is `stack()` them (see stack [documentation](https://unit8co.github.io/darts/generated_api/darts.timeseries.html?highlight=stack#darts.timeseries.TimeSeries.stack) if you'd like to have some fun sticking more time series together)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afed1f3c",
   "metadata": {
    "id": "2bcda017-de99-460c-8698-f771952b3465"
   },
   "source": [
    "üöÄ In this notebook, you've accomplished the following:\n",
    "\n",
    "üìö Data Loading and Visualization: You loaded time series data, created Darts TimeSeries objects, and visualized the data using Darts' visualization capabilities.\n",
    "\n",
    "üîÑ Data Manipulation: You performed various operations to manipulate time series data, including handling missing values, resampling, rolling window calculations, and feature engineering.\n",
    "\n",
    "‚è≥ Time Series Modeling and Forecasting: You explored different models such as NaiveSeasonal, ExponentialSmoothing, AutoARIMA, Prophet, and TBATS, fitting them to the data and generating forecasts.\n",
    "\n",
    "üîé Covariates and Holidays: You learned how to incorporate covariates and holidays into your time series models, leveraging their predictive power to improve forecast accuracy.\n",
    "\n",
    "üéä Conclusion: Working with time series doesn't have to be hard! Darts simplifies the process and empowers you to unlock insights from temporal data using an array of tools and models. So, dive in, explore, and unlock the potential of time series analysis! ‚ú®\n",
    "\n",
    "üåà Remember to have fun while exploring the captivating world of time series! If you encounter any challenges, Darts provides extensive documentation and a supportive community to assist you along the way. üåü\n",
    "\n",
    "Happy forecasting! üöÄüòä"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
